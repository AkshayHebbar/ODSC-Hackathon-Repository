GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type          | Params | Mode 
------------------------------------------------
0 | model | Float16Module | 2.6 B  | train
------------------------------------------------
5.3 M     Trainable params
2.6 B     Non-trainable params
2.6 B     Total params
10,478.667Total estimated model params size (MB)
582       Modules in train mode
0         Modules in eval mode
Metric val_loss improved. New best score: 1.100
Epoch 0, global step 200: 'validation_loss' reached 1.10000 (best 1.10000), saving model to '/root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=1.100-step=200-consumed_samples=2000.0.ckpt' as top 1
Metric val_loss improved by 0.071 >= min_delta = 0.001. New best score: 1.029
Epoch 0, global step 400: 'validation_loss' reached 1.02901 (best 1.02901), saving model to '/root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=1.029-step=400-consumed_samples=4000.0.ckpt' as top 1
Metric val_loss improved by 0.048 >= min_delta = 0.001. New best score: 0.981
Epoch 0, global step 600: 'validation_loss' reached 0.98120 (best 0.98120), saving model to '/root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=0.981-step=600-consumed_samples=6000.0.ckpt' as top 1
Metric val_loss improved by 0.027 >= min_delta = 0.001. New best score: 0.954
Epoch 0, global step 800: 'validation_loss' reached 0.95373 (best 0.95373), saving model to '/root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=0.954-step=800-consumed_samples=8000.0.ckpt' as top 1
Metric val_loss improved by 0.005 >= min_delta = 0.001. New best score: 0.949
Epoch 0, global step 1000: 'validation_loss' reached 0.94917 (best 0.94917), saving model to '/root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=0.949-step=1000-consumed_samples=10000.0.ckpt' as top 1
`Trainer.fit` stopped: `max_steps=1000` reached.
Restoring states from the checkpoint path at /root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=0.949-step=1000-consumed_samples=10000.0.ckpt
Restored all states from the checkpoint at /root/ODSC-Hackathon-Repository/results/checkpoints/megatron_gpt_peft_lora_tuning--validation_loss=0.949-step=1000-consumed_samples=10000.0.ckpt
